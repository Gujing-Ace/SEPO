{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ds_name', 'image', 'question', 'chosen', 'rejected', 'origin_dataset', 'origin_split', 'idx', 'image_path'],\n",
      "        num_rows: 6814\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_root = \"./data/RLAIF-V-Dataset\"\n",
    "data_file = [f'{data_root}/RLAIF-V-Dataset_{i:03d}.parquet' for i in range(1)]\n",
    "data = load_dataset('parquet', data_files=data_file)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'VQAv2': 1252, 'OK-VQA': 1249, 'LCS-558K': 1241, 'COCO': 1226, 'GQA': 471, 'OCR-VQA': 259, 'TextVQA': 248, 'sharegpt4v-web-celebrity': 224, 'sharegpt4v-textvqa': 218, 'sharegpt4v-web-landmark': 214, 'sharegpt4v-wikiart': 212})\n",
      "==================================\n",
      "OK-VQA: 18.33%\n",
      "TextVQA: 3.64%\n",
      "COCO: 17.99%\n",
      "LCS-558K: 18.21%\n",
      "sharegpt4v-wikiart: 3.11%\n",
      "VQAv2: 18.37%\n",
      "sharegpt4v-textvqa: 3.20%\n",
      "sharegpt4v-web-celebrity: 3.29%\n",
      "sharegpt4v-web-landmark: 3.14%\n",
      "GQA: 6.91%\n",
      "OCR-VQA: 3.80%\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "origin_dataset = data['train']['origin_dataset']\n",
    "counts = Counter(origin_dataset)\n",
    "print(counts)\n",
    "total_len = len(origin_dataset)\n",
    "propotions = {ds: num/total_len for ds, num in counts.items()}\n",
    "print('==================================')\n",
    "for ds, num in propotions.items():\n",
    "    print(f'{ds}: {num:.2%}')\n",
    "print('==================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Sampled dataset proportions: total count: 250\n",
      "COCO: 18.00%\n",
      "VQAv2: 18.40%\n",
      "LCS-558K: 18.00%\n",
      "sharegpt4v-textvqa: 3.20%\n",
      "TextVQA: 3.60%\n",
      "OK-VQA: 18.40%\n",
      "GQA: 6.80%\n",
      "OCR-VQA: 4.00%\n",
      "sharegpt4v-web-landmark: 3.20%\n",
      "sharegpt4v-web-celebrity: 3.20%\n",
      "sharegpt4v-wikiart: 3.20%\n",
      "=====================================\n",
      "=====================================\n",
      "Sampled dataset proportions: total count: 250\n",
      "VQAv2: 18.40%\n",
      "TextVQA: 3.60%\n",
      "sharegpt4v-web-landmark: 3.20%\n",
      "LCS-558K: 18.40%\n",
      "COCO: 18.00%\n",
      "OK-VQA: 18.40%\n",
      "sharegpt4v-wikiart: 3.20%\n",
      "OCR-VQA: 3.60%\n",
      "GQA: 6.80%\n",
      "sharegpt4v-web-celebrity: 3.20%\n",
      "sharegpt4v-textvqa: 3.20%\n",
      "=====================================\n",
      "=====================================\n",
      "Sampled dataset proportions: total count: 250\n",
      "COCO: 18.00%\n",
      "OCR-VQA: 3.60%\n",
      "VQAv2: 18.40%\n",
      "GQA: 7.20%\n",
      "LCS-558K: 18.40%\n",
      "sharegpt4v-web-landmark: 3.20%\n",
      "OK-VQA: 18.00%\n",
      "TextVQA: 3.60%\n",
      "sharegpt4v-textvqa: 3.20%\n",
      "sharegpt4v-web-celebrity: 3.20%\n",
      "sharegpt4v-wikiart: 3.20%\n",
      "=====================================\n",
      "=====================================\n",
      "Sampled dataset proportions: total count: 250\n",
      "VQAv2: 18.40%\n",
      "OK-VQA: 18.40%\n",
      "COCO: 18.00%\n",
      "sharegpt4v-web-celebrity: 3.60%\n",
      "LCS-558K: 18.00%\n",
      "OCR-VQA: 4.00%\n",
      "GQA: 6.80%\n",
      "TextVQA: 3.60%\n",
      "sharegpt4v-web-landmark: 3.20%\n",
      "sharegpt4v-textvqa: 3.20%\n",
      "sharegpt4v-wikiart: 2.80%\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "sample_num = 250*4\n",
    "df = pd.DataFrame(data['train'])\n",
    "_, df_sampled0 = train_test_split(df, test_size=sample_num, stratify=df['origin_dataset'], random_state=42)\n",
    "df_sampled01, df_sampled02 = train_test_split(df_sampled0, test_size=sample_num//2, stratify=df_sampled0['origin_dataset'], random_state=42)\n",
    "df_sampled1, df_sampled2 = train_test_split(df_sampled01, test_size=sample_num//4, stratify=df_sampled01['origin_dataset'], random_state=42)\n",
    "df_sampled3, df_sampled4 = train_test_split(df_sampled02, test_size=sample_num//4, stratify=df_sampled02['origin_dataset'], random_state=42)\n",
    "\n",
    "for df_sampled in (df_sampled1, df_sampled2, df_sampled3, df_sampled4):\n",
    "    counts = Counter(df_sampled['origin_dataset'])\n",
    "    total_count = len(df_sampled['origin_dataset'])\n",
    "    proportions = {ds: count / total_count for ds, count in counts.items()}\n",
    "    print(\"=====================================\")\n",
    "    print(\"Sampled dataset proportions: total count:\", total_count)\n",
    "    for ds, proportion in proportions.items():\n",
    "        print(f\"{ds}: {proportion:.2%}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49200b88a224e4bbbdc240b6c0c35ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb3a7842f4b46c1ac8e2396e4a80b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969f0a01a1c748ed84513b4391b54277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344bd5fd06cd499a8b5e909e3ca60afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_paths = {\n",
    "    'df_sampled1': './data/RLAIF_Sample/subset1',\n",
    "    'df_sampled2': './data/RLAIF_Sample/subset2',\n",
    "    'df_sampled3': './data/RLAIF_Sample/subset3',\n",
    "    'df_sampled4': './data/RLAIF_Sample/subset4',\n",
    "}\n",
    "for path, df in zip(save_paths.keys(), [df_sampled1, df_sampled2, df_sampled3, df_sampled4]):\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset.save_to_disk(save_paths[path])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
